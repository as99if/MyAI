FROM python:3.12-slim

WORKDIR /app

# Install system dependencies required for llama-cpp-python
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirement.txt .
RUN pip install --no-cache-dir --upgrade pip
RUN pip install setuptools
RUN pip installs -r requirement.txt

# Copy the application code
COPY . .

# Expose the port your FastAPI application will run on
EXPOSE 50001

# Command to start the inference server
CMD ["python", "-m", "serve"]