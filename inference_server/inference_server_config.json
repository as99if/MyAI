{
    "host": "0.0.0.0",
    "port": 50001,
    "interrupt_requests": true,
    "api_key": null,
    "root_path": "/Users/asifahmed/Development/MyAI/inference_server",
    "models": [
        {
            "model": "/Users/asifahmed/Development/MyAI/inference_server/models/vlm/gemma-3-1b/gemma-3-1b-it-Q4_K_M.gguf",
            "model_alias": "gemma-3-1b",
            "n_gpu_layers": -1,
            "hf_tokenizer_config_path": "/Users/asifahmed/Development/MyAI/inference_server/models/llm/gemma-3-1b/tokenizer_config.json"
        },
        {
            "model": "/Users/asifahmed/Development/MyAI/inference_server/models/vlm/gemma-3-4b/gemma-3-4b-it-Q4_K_M.gguf",
            "model_alias": "gemma-3-4b-multimodal",
            "clip_model_path": "/Users/asifahmed/Development/MyAI/models/vlm/gemma-3-4b/mmproj-BF16.gguf",
            "n_gpu_layers": -1,
            "hf_tokenizer_config_path": "/Users/asifahmed/Development/MyAI/inference_server/models/vlm/gemma-3-4b/tokenizer_config.json"
        }
    ]
}